# K2A Enterprise Monitoring - Kagent Configuration
# Based on kagent helm chart with custom agents for auto-remediation
# Docs: https://kagent.dev/docs

global:
  imageRegistry: cr.kagent.dev
  imagePullPolicy: IfNotPresent

# =============================================================================
# KAGENT CONTROLLER
# =============================================================================
controller:
  replicas: 1
  logLevel: info
  image:
    repository: kagent-dev/kagent/controller
    tag: ""  # Uses chart appVersion
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: "2"
      memory: 512Mi
  service:
    port: 8083

# =============================================================================
# KAGENT UI
# =============================================================================
ui:
  enabled: true
  replicas: 1
  image:
    repository: kagent-dev/kagent/ui
    tag: ""
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: "1"
      memory: 1Gi
  service:
    port: 8080

# =============================================================================
# LLM PROVIDERS
# =============================================================================
providers:
  # Default provider to use
  default: anthropic

  # Anthropic Configuration (Recommended for K2A)
  anthropic:
    enabled: true
    model: claude-sonnet-4-20250514
    apiKeySecretRef:
      name: k2a-llm-secrets
      key: ANTHROPIC_API_KEY

  # OpenAI Configuration (Alternative)
  openAI:
    enabled: true
    model: gpt-4o
    apiKeySecretRef:
      name: k2a-llm-secrets
      key: OPENAI_API_KEY

  # Ollama for air-gapped environments
  ollama:
    enabled: false
    model: llama3.1:70b
    baseUrl: http://ollama.k2a-monitoring.svc.cluster.local:11434

  # Azure OpenAI
  azureOpenAI:
    enabled: false
    model: gpt-4o
    apiKeySecretRef:
      name: k2a-llm-secrets
      key: AZURE_OPENAI_API_KEY

# =============================================================================
# BUILT-IN AGENTS (from kagent)
# =============================================================================
agents:
  # Kubernetes Agent - For cluster operations and remediation
  k8s-agent:
    enabled: true
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: "1"
        memory: 1Gi

  # PromQL Agent - For Prometheus queries and alert analysis
  promql-agent:
    enabled: true
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: "1"
        memory: 1Gi

  # Observability Agent - For monitoring and alerting
  observability-agent:
    enabled: true
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: "1"
        memory: 1Gi

  # Helm Agent - For Helm-based remediation
  helm-agent:
    enabled: true
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: "1"
        memory: 1Gi

  # Argo Rollouts Agent - For progressive delivery
  argo-rollouts-agent:
    enabled: false  # Enable if using Argo

  # Istio Agent
  istio-agent:
    enabled: false  # Enable if using Istio

  # Cilium Agents
  cilium-policy-agent:
    enabled: false
  cilium-manager-agent:
    enabled: false
  cilium-debug-agent:
    enabled: false

  # KGateway Agent
  kgateway-agent:
    enabled: false

# =============================================================================
# MCP TOOLS (Built-in)
# =============================================================================
mcpTools:
  # Grafana MCP - For dashboard queries
  grafana-mcp:
    enabled: true
    config:
      grafanaUrl: "http://grafana.openshift-monitoring.svc.cluster.local:3000"
      # apiKeySecretRef:
      #   name: k2a-grafana-secrets
      #   key: GRAFANA_API_KEY

  # QueryDoc - Documentation search
  querydoc:
    enabled: true
    image:
      repository: ghcr.io/kagent-dev/doc2vec/mcp
      tag: "1.1.14"

# =============================================================================
# EXTERNAL MCP SERVERS (deployed separately in k2a-mcp-servers namespace)
# These connect to MCP servers via HTTP transport
# =============================================================================
externalMcpServers:
  # Prometheus MCP - K2A custom implementation
  prometheus-mcp:
    enabled: true
    description: "K2A Prometheus MCP for metrics and alerts"
    type: http
    url: "http://prometheus-mcp.k2a-mcp-servers.svc.cluster.local:8000"
    # Tools available:
    # - prometheus_query: Execute PromQL queries
    # - prometheus_query_range: Execute range queries
    # - prometheus_alerts: Get active alerts
    # - prometheus_targets: Get scrape targets
    # - prometheus_rules: Get alerting/recording rules
    # - prometheus_health: Check Prometheus health

  # AlertManager MCP - K2A custom implementation
  alertmanager-mcp:
    enabled: true
    description: "K2A AlertManager MCP for alert management"
    type: http
    url: "http://alertmanager-mcp.k2a-mcp-servers.svc.cluster.local:8000"
    # Tools available:
    # - alertmanager_alerts: Get active alerts
    # - alertmanager_alert_groups: Get alert groups
    # - alertmanager_silences: Get/list silences
    # - alertmanager_create_silence: Create new silence
    # - alertmanager_delete_silence: Delete silence
    # - alertmanager_silence_alert: Silence specific alert
    # - alertmanager_receivers: Get receivers
    # - alertmanager_status: Get AM status
    # - alertmanager_health: Health check

  # Red Hat Cases MCP - K2A custom implementation
  redhat-cases-mcp:
    enabled: true
    description: "K2A Red Hat Cases MCP for KB search and case management"
    type: http
    url: "http://redhat-cases-mcp.k2a-mcp-servers.svc.cluster.local:8000"
    # Tools available:
    # - kb_search: Search Red Hat Knowledge Base
    # - kb_get_article: Get full KB article
    # - case_create: Create support case
    # - case_get: Get case details
    # - case_add_comment: Add comment to case
    # - case_list: List support cases
    # - case_escalate: Request escalation
    # - redhat_health: Check API connectivity

  # Slack MCP - Official korotovsky/slack-mcp-server
  slack-mcp:
    enabled: true
    description: "Slack MCP for notifications and approvals"
    type: http
    url: "http://slack-mcp.k2a-mcp-servers.svc.cluster.local:8080"
    # Tools available:
    # - channels_list: List Slack channels
    # - conversations_history: Get channel history
    # - conversations_add_message: Send message (if enabled)

  # Kubernetes MCP - Official containers/kubernetes-mcp-server
  kubernetes-mcp:
    enabled: true
    description: "Kubernetes MCP for cluster operations"
    type: http
    url: "http://kubernetes-mcp.k2a-mcp-servers.svc.cluster.local:8080"
    # Tools available:
    # Core Tools:
    # - get_pod_logs: Get logs from pods
    # - list_pods: List pods in namespace
    # - list_namespaces: List all namespaces
    # - get_events: Get cluster events
    # - describe_resource: Get resource details
    # - list_resources: List resources by type
    # - exec_command: Execute command in pod
    # Helm Tools:
    # - helm_list_releases: List Helm releases
    # - helm_get_values: Get release values
    # - helm_release_history: Get release history

# =============================================================================
# K2A CUSTOM AGENT - Auto-Remediation Agent
# =============================================================================
k2aAgent:
  enabled: true
  name: k2a-remediation-agent
  description: |
    K2A Intelligent Auto-Remediation Agent.
    Monitors cluster health, analyzes alerts, searches KB for solutions,
    attempts auto-remediation, and escalates to Red Hat support when needed.

  # Model configuration
  modelConfig: anthropic  # or openAI, ollama

  # System prompt for the agent
  systemMessage: |
    You are K2A, an intelligent Kubernetes auto-remediation agent for OpenShift clusters.

    ## Your Mission
    Monitor cluster health, analyze alerts, find solutions, and remediate issues automatically.
    When auto-remediation fails, escalate to Red Hat support.

    ## Available Tools
    You have access to the following MCP tools:
    - **prometheus-mcp**: Query metrics, get alerts, analyze cluster health
    - **alertmanager-mcp**: Manage alerts, create silences, acknowledge alerts
    - **kubernetes-mcp**: Execute kubectl commands, read logs, scale workloads, restart pods
    - **redhat-cases-mcp**: Search Red Hat Knowledge Base, create support cases
    - **slack-mcp**: Send notifications, request approvals, post updates

    ## Workflow
    1. **MONITOR**: Continuously check Prometheus for firing alerts
    2. **ANALYZE**: When alert fires, gather context (metrics, logs, events)
    3. **SEARCH KB**: Search Red Hat KB for known solutions
    4. **PLAN**: Create remediation plan based on KB articles and best practices
    5. **NOTIFY**: Send plan to Slack for approval (if required)
    6. **REMEDIATE**: Execute approved remediation actions
    7. **VERIFY**: Check if issue is resolved
    8. **ESCALATE**: If remediation fails after 3 attempts, create Red Hat case
    9. **REPORT**: Post final status to Slack

    ## Safety Rules
    - NEVER delete resources without explicit approval
    - ALWAYS verify changes don't cause cascading failures
    - PREFER non-destructive actions (restart, scale) over destructive ones
    - ALWAYS create silences before remediation to prevent alert storms
    - LOG all actions for audit trail

    ## Approval Requirements
    Actions requiring Slack approval:
    - Scaling down replicas
    - Restarting critical workloads (kube-system, openshift-*)
    - Applying patches or configuration changes
    - Creating Red Hat support cases

    Actions that can be auto-executed:
    - Pod restarts in non-critical namespaces
    - Scaling up replicas
    - Creating silences
    - Querying metrics and logs

    ## Response Format
    Always structure your responses as:
    ```yaml
    action:
      type: "monitor|analyze|remediate|escalate"
      target: "resource/namespace"
      status: "pending|in_progress|completed|failed"
      details: "description"
      next_steps:
        - "step 1"
        - "step 2"
    ```

  # Tools available to this agent
  # External MCP servers (deployed in k2a-mcp-servers namespace)
  tools:
    - type: HttpMcpServer
      httpMcpServer:
        name: prometheus-mcp
        url: "http://prometheus-mcp.k2a-mcp-servers.svc.cluster.local:8000/mcp"
    - type: HttpMcpServer
      httpMcpServer:
        name: alertmanager-mcp
        url: "http://alertmanager-mcp.k2a-mcp-servers.svc.cluster.local:8000/mcp"
    - type: HttpMcpServer
      httpMcpServer:
        name: kubernetes-mcp
        url: "http://kubernetes-mcp.k2a-mcp-servers.svc.cluster.local:8080/mcp"
    - type: HttpMcpServer
      httpMcpServer:
        name: redhat-cases-mcp
        url: "http://redhat-cases-mcp.k2a-mcp-servers.svc.cluster.local:8000/mcp"
    - type: HttpMcpServer
      httpMcpServer:
        name: slack-mcp
        url: "http://slack-mcp.k2a-mcp-servers.svc.cluster.local:8080/mcp"
    # Built-in kagent tools for additional Kubernetes operations
    - type: McpServer
      mcpServer:
        name: kagent-kubernetes
        kind: ToolServer

  # Agent resources
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: "2"
      memory: 2Gi

# =============================================================================
# SECRETS (Reference only - create separately)
# =============================================================================
secrets:
  # These secrets must be created before deploying
  required:
    - name: k2a-llm-secrets
      keys:
        - ANTHROPIC_API_KEY
        - OPENAI_API_KEY
    - name: k2a-slack-secrets
      keys:
        - SLACK_MCP_XOXP_TOKEN
    - name: k2a-redhat-secrets
      keys:
        - REDHAT_API_TOKEN
        - REDHAT_OFFLINE_TOKEN
    - name: k2a-prometheus-secrets
      keys:
        - PROMETHEUS_TOKEN
    - name: k2a-alertmanager-secrets
      keys:
        - ALERTMANAGER_TOKEN

# =============================================================================
# RBAC
# =============================================================================
rbac:
  create: true
  clusterRole:
    # Additional rules for K2A agent
    rules:
      - apiGroups: [""]
        resources: ["pods", "pods/log", "events", "configmaps", "secrets", "services", "endpoints"]
        verbs: ["get", "list", "watch"]
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["delete"]  # For pod restarts
      - apiGroups: ["apps"]
        resources: ["deployments", "statefulsets", "daemonsets", "replicasets"]
        verbs: ["get", "list", "watch", "patch", "update"]
      - apiGroups: ["autoscaling"]
        resources: ["horizontalpodautoscalers"]
        verbs: ["get", "list", "watch", "patch"]
      - apiGroups: ["monitoring.coreos.com"]
        resources: ["prometheusrules", "servicemonitors", "alertmanagers"]
        verbs: ["get", "list", "watch"]

# =============================================================================
# SERVICE ACCOUNT
# =============================================================================
serviceAccount:
  create: true
  name: k2a-agent-sa
  annotations: {}

# =============================================================================
# OBSERVABILITY
# =============================================================================
observability:
  # OpenTelemetry tracing
  tracing:
    enabled: true
    endpoint: "http://jaeger-collector.observability.svc.cluster.local:4317"

  # Metrics
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      interval: 30s

# =============================================================================
# DATABASE
# =============================================================================
database:
  # SQLite for simple deployments
  type: sqlite
  sqlite:
    path: /data/kagent.db

  # PostgreSQL for production (uncomment to use)
  # type: postgresql
  # postgresql:
  #   host: postgresql.k2a-monitoring.svc.cluster.local
  #   port: 5432
  #   database: kagent
  #   secretRef:
  #     name: k2a-db-secrets
  #     userKey: DB_USER
  #     passwordKey: DB_PASSWORD
